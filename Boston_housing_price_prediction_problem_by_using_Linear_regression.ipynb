{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "Gfst71Rbh5zR",
    "outputId": "f294adb6-16a6-4c4b-c782-2f8759ec31a9"
   },
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "#boston_dataset = load_boston()\n",
    "\n",
    "#google collab upload dataset\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "#import io\n",
    "\n",
    "# Check the uploaded file name\n",
    "#uploaded_file_name = list(uploaded.keys())[0]\n",
    "\n",
    "# Read the uploaded file using the correct name\n",
    "#df = pd.read_csv(io.BytesIO(uploaded[uploaded_file_name]))\n",
    "\n",
    "df = pd.read_csv(\"Boston.csv\")\n",
    "df.columns = [' ','crim','zn','indus','chas','nox','rm', 'age' , 'dis', 'rad' , 'tax', 'ptratio', 'black', 'lstat', 'medv']\n",
    "df\n",
    "\n",
    "import warnings\n",
    "#We do not want to see warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGhV-iJth8cE",
    "outputId": "6729ed4f-cc31-4a9d-d344-fa4d07c3548b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 14)\n",
      "(152, 14)\n",
      "(354,)\n",
      "(152,)\n",
      "             int64\n",
      "crim       float64\n",
      "zn         float64\n",
      "indus      float64\n",
      "chas         int64\n",
      "nox        float64\n",
      "rm         float64\n",
      "age        float64\n",
      "dis        float64\n",
      "rad          int64\n",
      "tax          int64\n",
      "ptratio    float64\n",
      "black      float64\n",
      "lstat      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('medv', axis=1)\n",
    "y = df['medv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = X_train.isnull().sum()\n",
    "\n",
    "\n",
    "# Check the data types\n",
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mruwckhwh_Hr",
    "outputId": "3a8e51ae-8820-48ac-f52c-42bc9fa25879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 14)\n",
      "(152, 14)\n",
      "(354,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "#Normalization or std. scalar - data preprocessing\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "#X_train=scaler.fit_transform(X_train)\n",
    "#X_test=scaler.fit_transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7yjTunhiCaz",
    "outputId": "ea1b1a6b-cdf1-4353-eacc-d8f3c42b7e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 128)               1920      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_output (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,721\n",
      "Trainable params: 22,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(14, ), activation='sigmoid', name='dense_1'))\n",
    "#model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n",
    "model.add(Dense(64, activation='relu', name='dense_2'))\n",
    "model.add(Dense(64, activation='relu', name='dense_3'))\n",
    "model.add(Dense(64, activation='relu', name='dense_4'))\n",
    "model.add(Dense(64, activation='relu', name='dense_5'))\n",
    "model.add(Dense(1, activation='linear', name='dense_output'))\n",
    "#model.compile(optimizer='RMSprop', loss='mse', metrics=['mae'])\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "for layer in model.layers:\n",
    "   if layer.name.startswith('pre_trained_model'):\n",
    "      layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_l00hwSkmYL",
    "outputId": "30d00126-2e52-4d9d-a02c-919224bcfaee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 33ms/step - loss: 489.8549 - mae: 19.9983 - val_loss: 283.8941 - val_mae: 14.2547\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 159.0110 - mae: 9.6084 - val_loss: 71.8575 - val_mae: 6.2941\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 63.9922 - mae: 5.7191 - val_loss: 67.0861 - val_mae: 6.0972\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 57.4794 - mae: 5.3935 - val_loss: 61.9969 - val_mae: 6.0756\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 52.4898 - mae: 5.2028 - val_loss: 72.2087 - val_mae: 5.4106\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 48.8051 - mae: 4.6929 - val_loss: 57.5275 - val_mae: 5.9039\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 45.9267 - mae: 4.6567 - val_loss: 55.1732 - val_mae: 6.4552\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 44.5877 - mae: 4.7603 - val_loss: 57.7328 - val_mae: 5.4880\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 42.5230 - mae: 4.4997 - val_loss: 63.3511 - val_mae: 5.1899\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 37.8935 - mae: 4.2304 - val_loss: 64.4496 - val_mae: 5.1074\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 35.2406 - mae: 4.0427 - val_loss: 57.7922 - val_mae: 5.0627\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 32.7245 - mae: 3.8741 - val_loss: 49.9639 - val_mae: 5.6859\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 35.2045 - mae: 4.2351 - val_loss: 50.2024 - val_mae: 6.2402\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 30.9582 - mae: 3.9818 - val_loss: 57.1398 - val_mae: 4.6532\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 28.2197 - mae: 3.6459 - val_loss: 50.1565 - val_mae: 4.8706\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 29.8996 - mae: 3.7436 - val_loss: 47.0326 - val_mae: 5.1952\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 25.8238 - mae: 3.5428 - val_loss: 50.8741 - val_mae: 4.5120\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 27.1599 - mae: 3.5947 - val_loss: 47.9877 - val_mae: 4.5957\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 23.8684 - mae: 3.3485 - val_loss: 48.6251 - val_mae: 4.4310\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 22.0810 - mae: 3.1632 - val_loss: 45.2805 - val_mae: 5.3237\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 25.0995 - mae: 3.6283 - val_loss: 45.0641 - val_mae: 4.8805\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 21.8770 - mae: 3.2565 - val_loss: 63.2507 - val_mae: 4.8339\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 22.1876 - mae: 3.1855 - val_loss: 51.4466 - val_mae: 4.0253\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 26.7707 - mae: 3.6535 - val_loss: 59.1426 - val_mae: 4.5096\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 19.9436 - mae: 3.0453 - val_loss: 42.8305 - val_mae: 4.3954\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 19.9725 - mae: 3.0938 - val_loss: 43.4415 - val_mae: 4.7525\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 25.7477 - mae: 3.7456 - val_loss: 43.2577 - val_mae: 4.4516\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 20.9671 - mae: 3.1412 - val_loss: 43.1473 - val_mae: 4.5345\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 21.7080 - mae: 3.3040 - val_loss: 42.5417 - val_mae: 4.4430\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 20.1380 - mae: 3.2054 - val_loss: 47.6319 - val_mae: 3.8848\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 18.4971 - mae: 2.9295 - val_loss: 46.8980 - val_mae: 3.9199\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 20.9940 - mae: 3.2199 - val_loss: 62.8375 - val_mae: 5.2619\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 22.2038 - mae: 3.4046 - val_loss: 43.3302 - val_mae: 3.7764\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.3704 - mae: 2.8421 - val_loss: 38.9347 - val_mae: 3.9758\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 21.1783 - mae: 3.1526 - val_loss: 56.6988 - val_mae: 4.7673\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 18.9714 - mae: 2.9788 - val_loss: 45.6382 - val_mae: 3.6874\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 20.4238 - mae: 3.0751 - val_loss: 38.0660 - val_mae: 3.7716\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.7556 - mae: 2.7578 - val_loss: 55.7392 - val_mae: 4.8652\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.5653 - mae: 2.8890 - val_loss: 45.7180 - val_mae: 3.9279\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 19.8433 - mae: 3.1452 - val_loss: 39.3847 - val_mae: 3.5867\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 19.2054 - mae: 3.0352 - val_loss: 54.0739 - val_mae: 4.8551\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.7726 - mae: 2.9084 - val_loss: 33.1900 - val_mae: 3.6755\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 18.5474 - mae: 2.9675 - val_loss: 33.1726 - val_mae: 3.7441\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.8828 - mae: 2.9265 - val_loss: 37.9871 - val_mae: 3.5936\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 17.3377 - mae: 2.8538 - val_loss: 36.3151 - val_mae: 3.4186\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.3990 - mae: 2.8147 - val_loss: 32.6051 - val_mae: 3.5083\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.4943 - mae: 2.7991 - val_loss: 31.0755 - val_mae: 3.4421\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.0491 - mae: 2.6054 - val_loss: 41.3773 - val_mae: 3.8356\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 21.3285 - mae: 3.3201 - val_loss: 29.3566 - val_mae: 3.5427\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1276 - mae: 2.6340 - val_loss: 34.3038 - val_mae: 4.8739\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 20.3417 - mae: 3.1122 - val_loss: 38.7920 - val_mae: 3.7801\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.9083 - mae: 2.5610 - val_loss: 28.9750 - val_mae: 3.9017\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.5254 - mae: 2.7612 - val_loss: 31.2938 - val_mae: 3.1733\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 13.5950 - mae: 2.3961 - val_loss: 28.4157 - val_mae: 4.1330\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 19.8865 - mae: 3.0711 - val_loss: 26.9968 - val_mae: 3.2218\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.7871 - mae: 2.6968 - val_loss: 26.5127 - val_mae: 3.6263\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.7222 - mae: 2.7185 - val_loss: 37.3879 - val_mae: 3.7956\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.8616 - mae: 2.9098 - val_loss: 28.8392 - val_mae: 3.1564\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 13.6406 - mae: 2.4167 - val_loss: 38.2396 - val_mae: 3.9110\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.4355 - mae: 2.7883 - val_loss: 26.8165 - val_mae: 2.9697\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.4842 - mae: 2.6743 - val_loss: 31.8408 - val_mae: 3.3649\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 13.6437 - mae: 2.4020 - val_loss: 28.3280 - val_mae: 3.1559\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.2702 - mae: 2.4516 - val_loss: 24.3940 - val_mae: 3.0137\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.2578 - mae: 2.5778 - val_loss: 41.4130 - val_mae: 4.4285\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 20.5324 - mae: 3.1628 - val_loss: 27.5364 - val_mae: 3.1292\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.1039 - mae: 2.3893 - val_loss: 37.9877 - val_mae: 4.1344\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2888 - mae: 2.6017 - val_loss: 22.2731 - val_mae: 3.1490\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.7948 - mae: 2.3341 - val_loss: 22.6661 - val_mae: 3.0867\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.3734 - mae: 2.8943 - val_loss: 23.2490 - val_mae: 3.0330\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.7859 - mae: 2.7645 - val_loss: 25.9872 - val_mae: 2.7850\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.2598 - mae: 2.3614 - val_loss: 23.4100 - val_mae: 3.0292\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.8052 - mae: 2.4607 - val_loss: 39.6493 - val_mae: 4.5487\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.3809 - mae: 2.6593 - val_loss: 32.9286 - val_mae: 3.7389\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.6719 - mae: 2.5996 - val_loss: 21.4857 - val_mae: 2.6298\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.2510 - mae: 2.2251 - val_loss: 20.1659 - val_mae: 3.4748\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.1702 - mae: 2.9624 - val_loss: 20.6994 - val_mae: 2.8544\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.6927 - mae: 2.3676 - val_loss: 38.6350 - val_mae: 4.4081\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.9137 - mae: 2.6581 - val_loss: 19.4894 - val_mae: 2.7829\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 15.5346 - mae: 2.6835 - val_loss: 22.0361 - val_mae: 2.5963\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.2247 - mae: 2.2349 - val_loss: 19.4368 - val_mae: 2.5282\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.0437 - mae: 2.5732 - val_loss: 20.6604 - val_mae: 3.8060\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.8658 - mae: 2.6401 - val_loss: 20.5914 - val_mae: 2.5980\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.2229 - mae: 2.3850 - val_loss: 24.8371 - val_mae: 3.0203\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 16.3798 - mae: 2.7948 - val_loss: 23.0705 - val_mae: 2.8958\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 13.3443 - mae: 2.5280 - val_loss: 21.7052 - val_mae: 2.5627\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.5940 - mae: 2.6275 - val_loss: 31.6078 - val_mae: 3.8520\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.4169 - mae: 2.5304 - val_loss: 28.5956 - val_mae: 3.4804\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.1857 - mae: 2.6025 - val_loss: 17.6545 - val_mae: 3.2524\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.5145 - mae: 2.3172 - val_loss: 18.3050 - val_mae: 2.2991\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 12.5118 - mae: 2.3444 - val_loss: 19.5554 - val_mae: 3.7321\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.6586 - mae: 2.7460 - val_loss: 16.8451 - val_mae: 2.6429\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 11.6160 - mae: 2.1947 - val_loss: 17.7284 - val_mae: 2.5173\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 11.4125 - mae: 2.1951 - val_loss: 16.5986 - val_mae: 2.8931\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 17.8803 - mae: 3.1200 - val_loss: 16.4453 - val_mae: 3.1252\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.6002 - mae: 2.6570 - val_loss: 16.2437 - val_mae: 3.1617\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 13.6900 - mae: 2.5292 - val_loss: 15.3385 - val_mae: 3.0379\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.2651 - mae: 2.3946 - val_loss: 18.4573 - val_mae: 2.3061\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 12.6213 - mae: 2.4842 - val_loss: 17.5394 - val_mae: 3.2106\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.7792 - mae: 2.9175 - val_loss: 16.4980 - val_mae: 2.2175\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 11.8421 - mae: 2.2259 - val_loss: 17.4952 - val_mae: 3.5899\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 64, epochs=100, validation_split= 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0G-utiHylACz",
    "outputId": "ed7e5cb7-664d-4504-97ba-3caad8292973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 29.6578 - mae: 3.9557\n",
      "Mean squared error on test data:  29.657752990722656\n",
      "Mean absolute error on test data:  3.955702066421509\n"
     ]
    }
   ],
   "source": [
    "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Mean squared error on test data: ', mse_nn)\n",
    "print('Mean absolute error on test data: ', mae_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
